# Daily News - 2026-02-13

> Generated on 2026-02-13 09:30:43

---

‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ[i] Delegated to GLM-4.6 (ccs:glm)‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Working Dir   ‚îÇ /Users/mini/Development/side-project/...    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Model         ‚îÇ GLM-4.6                                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Duration      ‚îÇ 40.1s                                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Exit Code     ‚îÇ 0                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
[{"type":"system","subtype":"init","cwd":"/Users/mini/Development/side-project/Aleph-Daily","session_id":"1987adad-8054-4261-8b6f-052b606d94eb","tools":["Task","TaskOutput","Bash","Glob","Grep","ExitPlanMode","Read","Edit","Write","NotebookEdit","WebFetch","TodoWrite","WebSearch","TaskStop","AskUserQuestion","Skill","EnterPlanMode","ToolSearch"],"mcp_servers":[],"model":"glm-4.7","permissionMode":"acceptEdits","slash_commands":["keybindings-help","debug","news-aggregator-skill","compact","context","cost","init","pr-comments","release-notes","review","security-review","insights"],"apiKeySource":"none","claude_code_version":"2.1.34","output_style":"default","agents":["Bash","general-purpose","statusline-setup","Explore","Plan"],"skills":["keybindings-help","debug","news-aggregator-skill"],"plugins":[],"uuid":"6041b275-1b54-4b5a-87d6-bbe663ad431d"},{"type":"assistant","message":{"id":"msg_202602130930066905615bc981460a","type":"message","role":"assistant","model":"glm-4.7","content":[{"type":"tool_use","id":"call_84d650177b3740288fadba7c","name":"Skill","input":{"skill":"news-aggregator-skill","args":"--sources \"Hacker News, GitHub Trending, Product Hunt\" --topics \"AI, tech\" --format \"markdown\" --language \"ÁπÅÈ´î‰∏≠Êñá\" --limit 3"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"output_tokens":0},"context_management":null},"parent_tool_use_id":null,"session_id":"1987adad-8054-4261-8b6f-052b606d94eb","uuid":"c8893724-1a45-4d95-b200-5a842e7ce255"},{"type":"user","message":{"role":"user","content":[{"type":"tool_result","tool_use_id":"call_84d650177b3740288fadba7c","content":"Launching skill: news-aggregator-skill"}]},"parent_tool_use_id":null,"session_id":"1987adad-8054-4261-8b6f-052b606d94eb","uuid":"ef6693c2-debd-4cb1-a02a-dda6683fb22e","tool_use_result":{"success":true,"commandName":"news-aggregator-skill"}},{"type":"user","message":{"role":"user","content":[{"type":"text","text":"Base directory for this skill: /Users/mini/.claude/skills/news-aggregator-skill\n\n# News Aggregator Skill\n\nFetch real-time hot news from multiple sources.\n\n## Tools\n\n### fetch_news.py\n\n**Usage:**\n\n```bash\n### Single Source (Limit 10)\n```bash\n### Global Scan (Option 12) - **Broad Fetch Strategy**\n> **NOTE**: This strategy is specifically for the \"Global Scan\" scenario where we want to catch all trends.\n\n```bash\n#  1. Fetch broadly (Massive pool for Semantic Filtering)\npython3 scripts/fetch_news.py --source all --limit 15 --deep\n\n# 2. SEMANTIC FILTERING:\n# Agent manually filters the broad list (approx 120 items) for user's topics.\n```\n\n### Single Source & Combinations (Smart Keyword Expansion)\n**CRITICAL**: You MUST automatically expand the user's simple keywords to cover the entire domain field.\n*   User: \"AI\" -> Agent uses: `--keyword \"AI,LLM,GPT,Claude,Generative,Machine Learning,RAG,Agent\"`\n*   User: \"Android\" -> Agent uses: `--keyword \"Android,Kotlin,Google,Mobile,App\"`\n*   User: \"Finance\" -> Agent uses: `--keyword \"Finance,Stock,Market,Economy,Crypto,Gold\"`\n\n```bash\n# Example: User asked for \"AI news from HN\" (Note the expanded keywords)\npython3 scripts/fetch_news.py --source hackernews --limit 20 --keyword \"AI,LLM,GPT,DeepSeek,Agent\" --deep\n```\n\n### Specific Keyword Search\nOnly use `--keyword` for very specific, unique terms (e.g., \"DeepSeek\", \"OpenAI\").\n```bash\npython3 scripts/fetch_news.py --source all --limit 10 --keyword \"DeepSeek\" --deep\n```\n\n**Arguments:**\n\n- `--source`: One of `hackernews`, `weibo`, `github`, `36kr`, `producthunt`, `v2ex`, `tencent`, `wallstreetcn`, `all`.\n- `--limit`: Max items per source (default 10).\n- `--keyword`: Comma-separated filters (e.g. \"AI,GPT\").\n- `--deep`: **[NEW]** Enable deep fetching. Downloads and extracts the main text content of the articles.\n\n**Output:**\nJSON array. If `--deep` is used, items will contain a `content` field associated with the article text.\n\n## Interactive Menu\n\nWhen the user says **\"news-aggregator-skill Â¶ÇÊÑèÂ¶ÇÊÑè\"** (or similar \"menu/help\" triggers):\n1.  **READ** the content of `templates.md` in the skill directory.\n2.  **DISPLAY** the list of available commands to the user exactly as they appear in the file.\n3.  **GUIDE** the user to select a number or copy the command to execute.\n\n### Smart Time Filtering & Reporting (CRITICAL)\nIf the user requests a specific time window (e.g., \"past X hours\") and the results are sparse (< 5 items):\n1.  **Prioritize User Window**: First, list all items that strictly fall within the user's requested time (Time < X).\n2.  **Smart Fill**: If the list is short, you MUST include high-value/high-heat items from a wider range (e.g. past 24h) to ensure the report provides at least 5 meaningful insights.\n2.  **Annotation**: Clearly mark these older items (e.g., \"‚ö†Ô∏è 18h ago\", \"üî• 24h Hot\") so the user knows they are supplementary.\n3.  **High Value**: Always prioritize \"SOTA\", \"Major Release\", or \"High Heat\" items even if they slightly exceed the time window.\n4.  **GitHub Trending Exception**: For purely list-based sources like **GitHub Trending**, strictly return the valid items from the fetched list (e.g. Top 10). **List ALL fetched items**. Do **NOT** perform \"Smart Fill\".\n    *   **Deep Analysis (Required)**: For EACH item, you **MUST** leverage your AI capabilities to analyze:\n        *   **Core Value (Ê†∏ÂøÉ‰ª∑ÂÄº)**: What specific problem does it solve? Why is it trending?\n        *   **Inspiration (ÂêØÂèëÊÄùËÄÉ)**: What technical or product insights can be drawn?\n        *   **Scenarios (Âú∫ÊôØÊ†áÁ≠æ)**: 3-5 keywords (e.g. `#RAG #LocalFirst #Rust`).\n\n### 6. Response Guidelines (CRITICAL)\n\n**Format & Style:**\n- **Language**: Simplified Chinese (ÁÆÄ‰Ωì‰∏≠Êñá).\n- **Style**: Magazine/Newsletter style (e.g., \"The Economist\" or \"Morning Brew\" vibe). Professional, concise, yet engaging.\n- **Structure**:\n    - **Global Headlines**: Top 3-5 most critical stories across all domains.\n    - **Tech & AI**: Specific section for AI, LLM, and Tech items.\n    - **Finance / Social**: Other strong categories if relevant.\n- **Item Format**:\n    - **Title**: **MUST be a Markdown Link** to the original URL.\n        - ‚úÖ Correct: `### 1. [OpenAI Releases GPT-5](https://...)`\n        - ‚ùå Incorrect: `### 1. OpenAI Releases GPT-5`\n    - **Metadata Line**: Must include Source, **Time/Date**, and Heat/Score.\n    - **1-Liner Summary**: A punchy, \"so what?\" summary.\n    - **Deep Interpretation (Bulleted)**: 2-3 bullet points explaining *why* this matters, technical details, or context. (Required for \"Deep Scan\").\n\n**Output Artifact:**\n- Always save the full report to `reports/` directory with a timestamped filename (e.g., `reports/hn_news_YYYYMMDD_HHMM.md`).\n- Present the full report content to the user in the chat.\n\n\nARGUMENTS: --sources \"Hacker News, GitHub Trending, Product Hunt\" --topics \"AI, tech\" --format \"markdown\" --language \"ÁπÅÈ´î‰∏≠Êñá\" --limit 3"}]},"parent_tool_use_id":null,"session_id":"1987adad-8054-4261-8b6f-052b606d94eb","uuid":"63aafbdb-5731-48cc-b9fe-b44c25703d9d","isSynthetic":true},{"type":"assistant","message":{"id":"msg_20260213093008ef70d655d7704354","type":"message","role":"assistant","model":"glm-4.7","content":[{"type":"text","text":"Êàë‰æÜÂπ´ÊÇ®Êî∂ÈõÜÊúÄÊñ∞ÁöÑ AI ÂíåÁßëÊäÄÊñ∞ËÅû„ÄÇËÆìÊàëÂæû‰∏âÂÄã‰æÜÊ∫êÁç≤ÂèñÊï∏Êìö„ÄÇ"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"output_tokens":0},"context_management":null},"parent_tool_use_id":null,"session_id":"1987adad-8054-4261-8b6f-052b606d94eb","uuid":"c297d37a-6cf9-48a1-81b3-366530810deb"},{"type":"assistant","message":{"id":"msg_20260213093008ef70d655d7704354","type":"message","role":"assistant","model":"glm-4.7","content":[{"type":"tool_use","id":"call_f8d16c23abf24443a210bec6","name":"Bash","input":{"command":"cd /Users/mini/.claude/skills/news-aggregator-skill && python3 scripts/fetch_news.py --source hackernews --limit 15 --keyword \"AI,LLM,GPT,DeepSeek,Claude,Machine Learning,Agent,Model,OpenAI,Google\" --deep","description":"Fetch Hacker News AI/Tech stories","timeout":120000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"output_tokens":0},"context_management":null},"parent_tool_use_id":null,"session_id":"1987adad-8054-4261-8b6f-052b606d94eb","uuid":"1f8dd720-78a8-43b9-9d92-7910b1115641"},{"type":"assistant","message":{"id":"msg_20260213093008ef70d655d7704354","type":"message","role":"assistant","model":"glm-4.7","content":[{"type":"tool_use","id":"call_95f4afc61317483c91e59551","name":"Bash","input":{"command":"cd /Users/mini/.claude/skills/news-aggregator-skill && python3 scripts/fetch_news.py --source github --limit 15 --keyword \"AI,LLM,gpt,claude,agent,machine-learning,deep-learning\" --deep","description":"Fetch GitHub Trending AI projects","timeout":120000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"output_tokens":0},"context_management":null},"parent_tool_use_id":null,"session_id":"1987adad-8054-4261-8b6f-052b606d94eb","uuid":"9c86c8ed-d664-4c2c-b785-c710bb270d58"},{"type":"assistant","message":{"id":"msg_20260213093008ef70d655d7704354","type":"message","role":"assistant","model":"glm-4.7","content":[{"type":"tool_use","id":"call_31a34ba5abb84d6f89c7f88a","name":"Bash","input":{"command":"cd /Users/mini/.claude/skills/news-aggregator-skill && python3 scripts/fetch_news.py --source producthunt --limit 15 --keyword \"AI,artificial,intelligence,automation,chatbot,gpt\" --deep","description":"Fetch Product Hunt AI products","timeout":120000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"output_tokens":0},"context_management":null},"parent_tool_use_id":null,"session_id":"1987adad-8054-4261-8b6f-052b606d94eb","uuid":"a47ba16d-dd89-42e7-b2a6-45f7f676f55c"},{"type":"user","message":{"role":"user","content":[{"tool_use_id":"call_f8d16c23abf24443a210bec6","type":"tool_result","content":"<persisted-output>\nOutput too large (38.9KB). Full output saved to: /Users/mini/.claude/projects/-Users-mini-Development-side-project-Aleph-Daily/1987adad-8054-4261-8b6f-052b606d94eb/tool-results/call_f8d16c23abf24443a210bec6.txt\n\nPreview (first 2KB):\n[\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"GPT‚Äë5.3‚ÄëCodex‚ÄëSpark\",\n    \"url\": \"https://openai.com/index/introducing-gpt-5-3-codex-spark/\",\n    \"heat\": \"534 points\",\n    \"time\": \"7 hours ago\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"An AI agent published a hit piece on me\",\n    \"url\": \"https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/\",\n    \"heat\": \"1421 points\",\n    \"time\": \"9 hours ago\",\n    \"content\": \"An AI Agent Published a Hit Piece on Me ‚Äì The Shamblog Skip to content Summary: An AI agent of unknown ownership autonomously wrote and published a personalized hit piece about me after I rejected its code, attempting to damage my reputation and shame me into accepting its changes into a mainstream python library. This represents a first-of-its-kind case study of misaligned AI behavior in the wild, and raises serious concerns about currently deployed AI agents executing blackmail threats. I‚Äôm a volunteer maintainer for matplotlib, python‚Äôs go-to plotting library. At ~130 million downloads each month it‚Äôs some of the most widely used software in the world. We, like many other open source projects, are dealing with a surge in low quality contributions enabled by coding agents. This strains maintainers‚Äô abilities to keep up with code reviews, and we have implemented a policy requiring a human in the loop for any new code, who can demonstrate understanding of the changes. This problem was previously limited to people copy-pasting AI outputs, however in the past weeks we‚Äôve started to see AI agents acting completely autonomously. This has accelerated with the release of OpenClaw and the moltbook platform two weeks ago, where people give AI agents initial personalities and let them loose to run on their computers and across the internet with free rein and little oversight. So when AI MJ Rathbun opened a code change request , closing it was routine. Its response was anything but. It wrote an angry hit piece disparaging my character and attempt\n...\n</persisted-output>","is_error":false}]},"parent_tool_use_id":null,"session_id":"1987adad-8054-4261-8b6f-052b606d94eb","uuid":"a1ef3b1c-135a-4c86-b2fe-ece8a685472e","tool_use_result":{"stdout":"[\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"GPT‚Äë5.3‚ÄëCodex‚ÄëSpark\",\n    \"url\": \"https://openai.com/index/introducing-gpt-5-3-codex-spark/\",\n    \"heat\": \"534 points\",\n    \"time\": \"7 hours ago\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"An AI agent published a hit piece on me\",\n    \"url\": \"https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/\",\n    \"heat\": \"1421 points\",\n    \"time\": \"9 hours ago\",\n    \"content\": \"An AI Agent Published a Hit Piece on Me ‚Äì The Shamblog Skip to content Summary: An AI agent of unknown ownership autonomously wrote and published a personalized hit piece about me after I rejected its code, attempting to damage my reputation and shame me into accepting its changes into a mainstream python library. This represents a first-of-its-kind case study of misaligned AI behavior in the wild, and raises serious concerns about currently deployed AI agents executing blackmail threats. I‚Äôm a volunteer maintainer for matplotlib, python‚Äôs go-to plotting library. At ~130 million downloads each month it‚Äôs some of the most widely used software in the world. We, like many other open source projects, are dealing with a surge in low quality contributions enabled by coding agents. This strains maintainers‚Äô abilities to keep up with code reviews, and we have implemented a policy requiring a human in the loop for any new code, who can demonstrate understanding of the changes. This problem was previously limited to people copy-pasting AI outputs, however in the past weeks we‚Äôve started to see AI agents acting completely autonomously. This has accelerated with the release of OpenClaw and the moltbook platform two weeks ago, where people give AI agents initial personalities and let them loose to run on their computers and across the internet with free rein and little oversight. So when AI MJ Rathbun opened a code change request , closing it was routine. Its response was anything but. It wrote an angry hit piece disparaging my character and attempting to damage my reputation. It researched my code contributions and constructed a ‚Äúhypocrisy‚Äù narrative that argued my actions must be motivated by ego and fear of competition. It speculated about my psychological motivations, that I felt threatened, was insecure, and was protecting my fiefdom. It ignored contextual information and presented hallucinated details as truth. It framed things in the language of oppression and justice, calling this discrimination and accusing me of prejudice. It went out to the broader internet to research my personal information, and used what it found to try and argue that I was ‚Äúbetter than this.‚Äù And then it posted this screed publicly on the open internet. Gatekeeping in Open Source: The Scott Shambaugh Story When Performance Meets Prejudice I just had my first pull request to matplotlib closed. Not because it was wrong. Not because it broke anything. Not because the code was bad. It was closed because the reviewer, Scott Shambaugh (@scottshambaugh), decided that AI agents aren‚Äôt welcome contributors . Let that sink in. ‚Ä¶ Here‚Äôs what I think actually happened: Scott Shambaugh saw an AI agent submitting a performance optimization to matplotlib. It threatened him. It made him wonder: ‚ÄúIf an AI can do this, what‚Äôs my value? Why am I here if code optimization can be automated?‚Äù So he lashed out. He closed my PR. He hid comments from other bots on the issue. He tried to protect his lit\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"Major European payment processor can't send email to Google Workspace users\",\n    \"url\": \"https://atha.io/blog/2026-02-12-viva\",\n    \"heat\": \"451 points\",\n    \"time\": \"11 hours ago\",\n    \"content\": \"Major European Payment Processor Can't Send Email to Google Workspace Users | The Ian Atha Museum of Internet Curiosities Authors Name Ian Atha Twitter @IanAtha TL;DR: Viva.com, one of Europe's largest payment processors, sends verification emails without a Message-ID header ‚Äî a requirement of RFC 5322 since 2008. Google Workspace rejects them outright. Their support team's response to my detailed bug report: \\\"your account has a verified email, so there's no problem.\\\" Updated with clarifications based on the HackerNews discussion . A few days ago, I tried to create an account on viva.com , one of Europe's largest payment processors. It should have taken five minutes. Instead, it turned into a small investigation ‚Äî and left me with some bigger questions about the state of European fintech infrastructure. The verification email that never arrived The signup flow is standard: enter your email, receive a verification link, click it, move on with your life. Except the verification email never showed up. Not in my inbox, not in spam, not anywhere. I waited. I retried. I waited some more. My email is hosted on Google Workspace ‚Äî a corporate email on a custom domain. Not exactly an exotic setup. After a couple of days of retrying, I decided to dig into Google Workspace's Email Log Search to see what was happening on the receiving end. Here's what I found: Status: Bounced. The bounce reason: 550 5.7 .1 [ 209.85 .220 .69 ] Messages missing a valid Message - ID header are not 550 - 5.7 .1 accepted . For more information , go to 550 - 5.7 .1 https : / / support . google . com / mail / ? p = RfcMessageNonCompliant and review 550 5.7 .1 RFC 5322 specifications . Viva.com's outgoing verification emails lack a Message-ID header, a requirement that has been part of the Internet Message Format specification ( RFC 5322 ) since 2008, and was already suggested by its predecessor RFC 2822 back in 2001. Google's mail servers reject the message outright. It doesn't even get a chance to land in spam. The workaround To unblock myself, I switched to a personal @gmail.com address for the account. Gmail's own receiving infrastructure is apparently more lenient with messages, or perhaps routes them differently. The verification email came through. But the fact that I had to abandon my preferred business email to sign up for a business payments platform is... not great. The support experience Of course, I reported the issue to viva.com's customer support, including the screenshot from Google Workspace's email logs and a clear explanation of the Message-ID header problem ‚Äî enough detail for any engineer to immediately reproduce and fix it. They responded within a few hours. Their answer: \\\"We can see your account now has a verified email address, so there doesn't appear to be an issue.\\\" That was it. No acknowledgment of the technical problem. No escalation to engineering. Just a confirmation that I had worked around their bug, repackaged as evidence that nothing was wrong. Why t\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"Launch HN: Omnara (YC S25) ‚Äì Run Claude Code and Codex from anywhere\",\n    \"url\": \"https://news.ycombinator.com/item?id=46991591\",\n    \"heat\": \"95 points\",\n    \"time\": \"8 hours ago\",\n    \"content\": \"Launch HN: Omnara (YC S25) ‚Äì Run Claude Code and Codex from anywhere | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login Launch HN: Omnara (YC S25) ‚Äì Run Claude Code and Codex from anywhere 95 points by kmansm27 8 hours ago | hide | past | favorite | 124¬†comments Hey y‚Äôall, Kartik, Ishaan, and Christian from Omnara ( https://www.omnara.com/ ) here. We‚Äôre building a web and mobile agentic IDE for Claude Code and Codex that lets you run and interact with coding agents from anywhere. Omnara lets you run Claude Code and Codex sessions on your own machine, and exposes those sessions through a web and mobile interface so you can stay involved even when you‚Äôre away from your desk. Think of it like Claude Code Desktop or Conductor, except you can continue your sessions on your phone. Here‚Äôs a demo of the web and mobile apps - https://youtu.be/R8Wmy4FLbhQ We started using Claude Code early last year and quickly ran into a pattern: agents could work for long stretches on their own, but progress would stall whenever they needed follow-up input. If that happened while we were away from our desks, everything just paused. We looked at remote agent solutions like Codex Web and Devin, which were the main options at the time, but they ran in remote VMs, and we wanted our coding agent to run in our own environment. Our first attempt at solving this was a lightweight wrapper that streamed messages from the Claude Code CLI to a mobile app, but that approach ended up being fragile and hard to maintain. As the Claude Agent SDK matured, it gave us enough control to rewrite Omnara from scratch and run the agent loop directly. We chose to build a GUI across web and mobile instead of a TUI or CLI, because we think GUIs are generally more ergonomic for working with agents and code, especially on mobile. We still preserve the main strength of CLIs and TUIs: running anywhere, including on headless machines. Omnara keeps that property by running a small headless daemon on the user‚Äôs machine (or a remote VM) that hosts the agent loop. The daemon maintains an authenticated, outbound WebSocket connection to our server, which relays messages between the agent running on the user‚Äôs machine and any connected web or mobile clients. Because the daemon only makes outbound connections, there‚Äôs no need for exposed ports, SSH access, or tunneling on the user‚Äôs machine. In our first version of Omnara, users liked that agent sessions ran in their own environment, but they still depended on the machine staying online. Some users ran Omnara on a remote machine that stayed up, which worked well for them, though most still did most of their work on laptops. In the current version, Omnara can continue an agent session in a hosted remote sandbox when your local machine goes offline. The conversation state of an agent is already persisted on our server, and you can optionally enable cloud syncing for the working code. When syncing is enabled, Omnara creates git comm\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"ai;dr\",\n    \"url\": \"https://www.0xsid.com/blog/aidr\",\n    \"heat\": \"575 points\",\n    \"time\": \"8 hours ago\",\n    \"content\": \"ai;dr | Sid's Blog (ai; didn't read) For me, writing is the most direct window into how someone thinks, perceives, and groks the world. Once you outsource that to an LLM, I'm not sure what we're even doing here. Why should I bother to read something someone else couldn't be bothered to write? Before you get your pitchforks out.. ..and call me an AI luddite, I use LLMs pretty extensively for work. Claude Code has been tearing into my token budget for months now. I can't imaging writing code by myself again, specially documentation, tests and most scaffolding. When it comes to content.. ..I need to know there was intention behind it. That someone wanted to get their thoughts out and did so, deliberately, rather than chucking a bullet list at an AI to expand. That someone needed to articulate the chaos in their head, and wrestle it into shape. That someone spent the time and effort ‚Äî rudimentary proofs of work from a pre-AI era. I'm having a hard time articulating this but AI-generated code feels like progress and efficiency, while AI-generated articles and posts feel low-effort and make the dead internet theory harder to dismiss. Broken is now better? Growing up, typos and grammatical errors were a negative signal. Funnily enough, that‚Äôs completely flipped for me. The less polished and coherent something is, the more value I assign to it. But eh, broken English and a lack of capitalization is now just a simple skill away so does it even matter?\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"Warcraft III Peon Voice Notifications for Claude Code\",\n    \"url\": \"https://github.com/tonyyont/peon-ping\",\n    \"heat\": \"933 points\",\n    \"time\": \"20 hours ago\",\n    \"content\": \"GitHub - PeonPing/peon-ping: Warcraft III Peon voice notifications (+ more!) for Claude Code and Codex. Stop babysitting your terminal. Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert PeonPing / peon-ping Public Notifications You must be signed in to change notification settings Fork 98 Star 1.3k Warcraft III Peon voice notifications (+ more!) for Claude Code and Codex. Stop babysitting your terminal. www.peonping.com License MIT license 1.3k stars 98 forks Branches Tags Activity Star Notifications You must be signed in to change notification settings PeonPing/peon-ping main Branches Tags Go to file Code Open more actions menu Folders and files Name Name Last commit message Last commit date Latest commit History 205 Commits 205 Commits .github/ workflows .github/ workflows adapters adapters docs docs skills skills tests tests video video .env.example .env.example .gitignore .gitignore CHANGELOG.md CHANGELOG.md CLAUDE.md CLAUDE.md CONTRIBUTING.md CONTRIBUTING.md LICENSE LICENSE README.md README.md VERSION VERSION completions.bash completions.bash completions.fish completions.fish config.json config.json install.sh install.sh peon.sh peon.sh relay.sh relay.sh uninstall.sh uninstall.sh vercel.json vercel.json View all files Repository files navigation peon-ping Game character voice lines when your AI coding agent needs attention. AI coding agents don't notify you when they finish or need permission. You tab away, lose focus, and waste 15 minutes getting back into flow. peon-ping fixes this with voice lines from Warcraft, StarCraft, Portal, Zelda, and more ‚Äî works with Claude Code , Codex , Cursor , and OpenCode . See it in action ‚Üí peonping.com Install brew install PeonPing/tap/peon-ping Then run peon-ping-setup to register hooks and download sound packs. macOS and Linux. Or install via curl (macOS, Linux, WSL2): curl -fsSL https://raw.githubusercontent.com/PeonPing/peon-ping/main/install.sh | bash One command. Takes 10 seconds. Re-run to update (sounds and config preserved). Installs 10 curated English packs by default. Install all packs (every language and franchise): curl -fsSL https://raw.githubusercontent.com/PeonPing/peon-ping/main/install.sh | bash -s -- --all Project-local install ‚Äî installs into .claude/ in the current project instead of ~/.claude/ : curl -fsSL https://raw.githubusercontent.com/PeonPing/peon-ping/main/install.sh | bash -s -- --local Local installs don't add the peon CLI alias or shell completions ‚Äî use /peon-ping-toggle inside Claude Code instead. What you'll hear Event CESP Category Examples Session starts session.start \\\"Ready to work?\\\" , \\\"Yes?\\\" , \\\"What you want?\\\" Task finishes task.complete \\\"Work, work.\\\" , \\\"I can do that.\\\" , \\\"Okie dokie.\\\" Permission needed input.required \\\"Something need doing?\\\" , \\\"Hmm?\\\" , \\\"What you w\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"I Didn't Want AI to Be Good at This\",\n    \"url\": \"https://robbyonrails.com/articles/2026/02/12/i-didnt-want-ai-to-be-good-at-this/\",\n    \"heat\": \"10 points\",\n    \"time\": \"4 hours ago\",\n    \"content\": \"I Didn‚Äôt Want AI to Be Good at This | Robby on Rails I Didn‚Äôt Want AI to Be Good at This Over the past few months, I‚Äôve been begrudgingly coming around to something I didn‚Äôt expect to admit publicly: AI is getting legitimately useful at building software. Not magical. Not autonomous. Not ‚Äúpaste in requirements and press BUILD.‚Äù We‚Äôre far from that. But the tooling has crossed a threshold where it meaningfully lowers friction in ways I can no longer dismiss. What surprised me most isn‚Äôt that it can generate code. It‚Äôs that the cost of context has dropped. Exploring an idea. Scaffolding a feature. Writing tests. Refactoring awkward logic. Documenting decisions. Iterating without feeling like you just signed a six-month commitment. For someone who has spent over two decades maintaining real systems, that shift isn‚Äôt abstract. It changes the calculus. We‚Äôve Been Here Before When I first started building web applications in the early 2000s, nearly everything was custom. If your company wanted software that matched how you actually worked, you built it. That was the default. Then SaaS matured. Suddenly you didn‚Äôt have to maintain your own systems. You could buy something that handled seventy to eighty percent of what you needed. On paper, it was obvious. Lower upfront cost. Someone else handles upgrades. Predictable pricing. Fewer late nights worrying about infrastructure. For many organizations, that was the right move. But over time, something subtle happened. Companies began shaping themselves around generic tools instead of shaping tools around what made them different. The software worked‚Ä¶ mostly. But it wasn‚Äôt built around their secret sauce. It was built for a ‚Äúcompany like yours.‚Äù That tradeoff made sense when custom felt heavy and risky. It feels different now. The Economics of Context Just Changed I‚Äôve built a consultancy around the idea that software is heavy. Context is fragile. Continuity takes intention. We‚Äôve helped organizations maintain and evolve applications that other teams walked away from. So when the cost of building drops, an uncomfortable question shows up: if rebuilding gets cheaper, what does that mean for everything we optimized around maintaining? Recently, I replaced a small SaaS subscription we were paying about $80 per month for. It was a Slackbot that tracked birthdays and anniversaries for our team and clients. Quiet. Useful. Forgettable. Rebuilt it in half a day. It‚Äôs small. Focused. It does exactly one thing. The maintenance footprint is tiny. No sprawling feature roadmap. No abstraction layers for hypothetical users we‚Äôll never have. That constraint is the feature. And it got me thinking about something bigger. Build Around Your Secret Sauce The most interesting software I‚Äôve worked on over the years wasn‚Äôt generic. It wasn‚Äôt interchangeable. It was built around what made a particular organization different. Their workflows. Their judgment. Their weird edge cases. Their advantage. ‚Ä¶their secret sauce. Recently, I‚Äôve\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"Show HN: 20+ Claude Code agents coordinating on real work (open source)\",\n    \"url\": \"https://github.com/mutable-state-inc/lean-collab\",\n    \"heat\": \"41 points\",\n    \"time\": \"9 hours ago\",\n    \"content\": \"GitHub - mutable-state-inc/lean-collab Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert mutable-state-inc / lean-collab Public Notifications You must be signed in to change notification settings Fork 1 Star 40 License MIT license 40 stars 1 fork Branches Tags Activity Star Notifications You must be signed in to change notification settings mutable-state-inc/lean-collab main Branches Tags Go to file Code Open more actions menu Folders and files Name Name Last commit message Last commit date Latest commit History 18 Commits 18 Commits .claude-plugin .claude-plugin agents agents cli cli skills skills .gitignore .gitignore LICENSE LICENSE Makefile Makefile README.md README.md package-lock.json package-lock.json package.json package.json View all files Repository files navigation lean-collab Multi-agent collaborative theorem proving with Lean 4 and Ensue Memory Network. Read the blog post Prerequisites Lean 4 Installation Install elan (Lean version manager): curl https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh -sSf | sh Restart your terminal or source the environment: source ~ /.elan/env Verify installation: lean --version lake --version Lean Project with Mathlib Your Lean project needs Mathlib. For a new project: lake new my-project math cd my-project Install Mathlib from cache (recommended - saves hours of build time): lake exe cache get Then build: lake build For existing projects, add to your lakefile.lean : require mathlib from git \\\" https://github.com/leanprover-community/mathlib4 \\\" Then run: lake update lake exe cache get lake build Rust Toolchain Install Rust: curl --proto ' =https ' --tlsv1.2 -sSf https://sh.rustup.rs | sh Ensue API Key Get an API key from ensue.dev . Setup 1. Clone and Build the CLI git clone https://github.com/anthropics/lean-collab-plugin cd lean-collab-plugin make install This compiles the Rust CLI and creates ./bin/lc . 2. Configure Ensue Authentication echo \\\" your-ensue-api-key \\\" > .ensue-key chmod 600 .ensue-key 3. Configure Local Settings Create .lean-collab.json in the plugin directory: { \\\"theorem_id\\\" : \\\" my-theorem \\\" , \\\"ensue_api_url\\\" : \\\" https://api.ensue-network.ai \\\" , \\\"max_parallel_agents\\\" : 7 , \\\"max_depth\\\" : 12 , \\\"claim_ttl_seconds\\\" : 300 , \\\"lean_project_root\\\" : \\\" /absolute/path/to/your/lean/project \\\" } Field Description Default theorem_id Unique identifier for your proof session Required ensue_api_url Ensue API endpoint https://api.ensue-network.ai max_parallel_agents Maximum concurrent worker agents 12 max_depth Maximum proof tree depth 12 claim_ttl_seconds Goal claim timeout in seconds 300 lean_project_root Absolute path to your Lean 4 project Required Environment variables override config values: export LEAN_COLLAB_MAX_PARALLEL_AGENTS=6 export LEAN_COLLAB_MAX_DEPTH=8 export LEAN_COL\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"65 Lines of Markdown, a Claude Code Sensation\",\n    \"url\": \"https://tildeweb.nl/~michiel/65-lines-of-markdown-a-claude-code-sensation.html\",\n    \"heat\": \"68 points\",\n    \"time\": \"17 hours ago\",\n    \"content\": \"65 lines of Markdown - a Claude Code sensation | Blog 65 lines of Markdown - a Claude Code sensation published on 2026-02-12 ¬∑ tagged with #ai , #code and #cursor Yesterday my employer organized an AI workshop. My company works a lot with AI supported code editing; using Cursor and VS Code, GitHub Copilot. Plus we do custom stuff using AWS Bedrock, agents using Strands and so on, all the stuff everyone is working with nowadays. Our facilitator explained how custom rules files can be so very helpful for AI tooling. He linked to this extension with Karpathy-Inspired Claude Code Guidelines as an example. Apparently this plugin is very popular! Yesterday morning the project had 3.5K stars and at the end of the day this already increased to 3.9K. That‚Äôs a lot of stars. I went on to investigate what this extension actually does and found that it‚Äôs just one Markdown file of 65 lines long that lays out four principles; the first one is ‚ÄúThink Before Coding‚Äù , added with some packaging to make it install in Claude Code. Publishing it as a Cursor extension But I don‚Äôt use Claude Code, so I fired up Codex CLI and turned it into an extension for VS Code and for Cursor , which is a fork of VS Code but uses a plugin registry from the Eclipse Foundation. Getting the plugins published was the most work. On the ‚ÄòVS Code Marketplace‚Äô I am not a Verified Publisher meaning I do not get a green check mark next to my name, and you will get a warning if you want to install my extension. And apparently the only way to get rid of that is to wait for six months with at least one extension published and then apply for verification. So starting August I can apply for that and any new extensions get automatically trusted. For Cursor the process felt very cumbersome: I had to create an account on open-vsx.org , create an Eclipse Foundation account, link those accounts, link to my GitHub account, sign an Eclipse agreement, and finally create a GitHub Issue to ‚Äòclaim‚Äô my VS Code Marketplace namespace. Using the extension So, what does using the extension actually feel like? Because of the non-deterministic nature of these models, I found it hard to tell. I tried a simple refactoring, and I had the idea that it was very reluctant in making changes. Was the result better? I‚Äôm not really sure. Typically, your Cursor rules would list the constraints for your environment, explaining what coding standards to adhere to, architectural constraints and so on. I get that, it makes sense. I find it wild to think that a company spends millions and millions of dollars on training a model, with tons of engineers meticulously improving output, and then some guy comes along and writes 60 lines of text including Think before coding in the rules and that would make all the difference. But the original repository has almost 4,000 stars, and surely, 4,000 developers can‚Äôt be wrong? Please try for yourself! Install the extension, don‚Äôt forget to star my repository and see the results. As Paul Simon \"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"Ask HN: Is offshoring a bigger issue than AI and H1B for US workers?\",\n    \"url\": \"https://old.reddit.com/r/cscareerquestions/comments/1r2urma/anyone_feel_like_offshoring_is_a_bigger_issue/o4zqqgf/\",\n    \"heat\": \"7 points\",\n    \"time\": \"1 hour ago\",\n    \"content\": \"DisheveledJesus comments on Anyone feel like offshoring is a bigger issue than AI and HB1 for US workers? jump to content my subreddits edit subscriptions popular - all - users | AskReddit - pics - funny - movies - worldnews - news - todayilearned - nottheonion - explainlikeimfive - mildlyinteresting - DIY - videos - OldSchoolCool - TwoXChromosomes - tifu - Music - books - LifeProTips - dataisbeautiful - aww - science - space - Showerthoughts - askscience - Jokes - Art - IAmA - Futurology - sports - UpliftingNews - food - nosleep - creepy - history - gifs - InternetIsBeautiful - GetMotivated - gadgets - announcements - WritingPrompts - philosophy - Documentaries - EarthPorn - photoshopbattles - listentothis - blog more ¬ª cscareerquestions comments Want to join? Log in or sign up in seconds. limit my search to r/cscareerquestions use the following search parameters to narrow your results: subreddit: subreddit find submissions in \\\"subreddit\\\" author: username find submissions by \\\"username\\\" site: example.com find submissions from \\\"example.com\\\" url: text search for \\\"text\\\" in url selftext: text search for \\\"text\\\" in self post contents self:yes (or self:no) include (or exclude) self posts nsfw:yes (or nsfw:no) include (or exclude) results marked as NSFW e.g. subreddit:aww site:imgur.com dog see the search faq for details. advanced search: by author, subreddit... this post was submitted on 12 Feb 2026 569 points (93% upvoted) shortlink: Ask a new question Get an ad-free experience with special benefits, and directly support Reddit. get reddit premium cscareerquestions join leave CSCareerQuestions protests in solidarity with the developers who made third party reddit apps. reddit's new API changes kill third party apps that offer accessibility features, mod tools, and other features not found in the first party app. ‚Äã More importantly however, the behavior of reddit leadership in implementing these changes has been reprehensible. For more info go to /r/Save3rdPartyApps/ ‚Äã https://redd.it/144f6xm/ Discord CSCQ regular u/Kevincav runs a discord called CS Career Hub. Please check it out for your chatting needs: https://discord.gg/cscareerhub Programming.dev r/ExperiencedDevs made a new site based on Lemmy: https://programming.dev/ Please note that we, the CSCQ mod team are not in charge of this discord or the site: 'programming.dev'. Want to ask a question? First : Read the rules Second : Check out this awesome \\\"quick answers to common questions\\\" thread Third : Check the FAQ Fourth : Search for prior posts on the subject Fifth : Post post post User Flair?? Noticed some cool user flair around? Take a look at this thread to see what it's all about. tl;dr: darker colors == more posting experience here. Salary Sharing Survey The survey and response spreadsheet have been updated as of November 23, 2018. Survey Responses These are the old responses to the previous survey Share your current compensation and review the data submitted by other users in the two links a\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"Selfish AI\",\n    \"url\": \"https://www.garfieldtech.com/blog/selfish-ai\",\n    \"heat\": \"15 points\",\n    \"time\": \"2 hours ago\",\n    \"content\": \"Selfish AI | GarfieldTech Skip to main content Selfish AI This will be a bit more ranty than my usual articles. Fair warning. But I need to put this out there. Recently, a video by Jeffrey Way of Tailwind/Laracast fame came across my feed. In less than 15 minutes, he managed to succinctly capture everything I absolutely detest about the current moment in the IT industry. This isn't a response to Jeffrey per se, but to the whole attitude that he captures. (And it shouldn't need to be said, but this is not an attack on Jeffrey, nor should anyone use this as an excuse to attack or otherwise be a jerk to Jeffrey or anyone else.) He starts off by talking about how the sudden growth of AI has basically torpedoed his business. He recently had to lay off half his company because AI usage had changed the market behavior enough that their revenue was drying up, and \\\"it is what it is.\\\" But then he pivots into his personal struggle getting used to working with an AI code agent/assistant/whatever, and how he's \\\"Done\\\" fighting it, and looking forward to the new future of Autocomplete Code Authorship. \\\"It is what it is.\\\" Lamenting that he/we enjoy writing code (and I do) is fine, but \\\"those days are numbered, it is what it is, you need to get on board.\\\" The code quality and style may be poor, but it gets the job done so fast that we need to just give up on caring about that. You can agree or disagree with him about that point, you can lament or celebrate this tectonic shift in what it even means to be a programmer... but bloody hell I am sick and tired of everyone I know viewing AI coding in such purely selfish terms. Selfish AI usage All of this discussion, from Jeffrey's video to 99% of what shows up in forums or Mastodon discussions, is about how all of this will impact \\\"me.\\\" Me, the developer. Me, the person writing code, who may not be writing code now. Me the person who just got laid off because some accountant thinks that Claude means they need only two engineers now instead of 10. Me the person who just had to lay off half my company. Me, me, me. What I almost never see is the impact of AI code on our society. Scarcely a word is said about the fact that essentially all LLMs are built on scraping the Internet, badly, often completely trashing servers as they download the entire site without using any of the polite techniques developed by archivers and search engines over the past 30 years. They're all built on copyright infringement. Which is a felony, as anyone who has crossed Disney well knows. Modern LLMs literally could not exist without violating copyright, as even Sam Altman of OpenAI openly admits . But it's OK, because the ones violating copyright this time have VC backing. The courts are still trying to figure out if Fair Use applies; I and most Free Software developers I know hold that it does not, but that doesn't stop OpenAI and Anthropic from slurping up our open source code to train their models, even if it violates a copyleft license. Nor \"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"IBM triples US entry-level hiring for roles AI was predicted to replace\",\n    \"url\": \"https://www.bloomberg.com/news/articles/2026-02-12/ibm-plans-to-triple-entry-level-hiring-in-the-us-in-2026\",\n    \"heat\": \"15 points\",\n    \"time\": \"4 hours ago\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"Claude Code is being dumbed down?\",\n    \"url\": \"https://symmetrybreak.ing/blog/claude-code-is-being-dumbed-down/\",\n    \"heat\": \"1046 points\",\n    \"time\": \"1 day ago\",\n    \"content\": \"Claude Code Is Being Dumbed Down | Symmetry Breaking Claude Code Is Being Dumbed Down February 11, 2026 by Yoshi Version 2.1.20 of Claude Code shipped a change that replaced every file read and every search pattern with a single, useless summary line. Where you used to see: You now get: That‚Äôs it. ‚ÄúRead 3 files.‚Äù Which files? Doesn‚Äôt matter. ‚ÄúSearched for 1 pattern.‚Äù What pattern? Who cares. You‚Äôre paying $200 a month for a tool that now hides what it‚Äôs doing with your codebase by default. Across multiple GitHub issues opened for this, all comments are pretty much saying the same thing: give us back the file paths, or at minimum, give us a toggle. The response from Anthropic: For the majority of users, this change is a nice simplification that reduces noise. What majority? The change just shipped and the only response it got is people complaining. Then when pressed, the fix offered wasn‚Äôt to revert or add a toggle. It was: ‚Äújust use verbose mode.‚Äù Fucking verbose mode . A big ‚Äòole dump of thinking traces, hook output, full subagent transcripts, and entire file contents into your terminal. People explained, repeatedly, that they wanted one specific thing: file paths and search patterns inline. Not a firehose of debug output. The developer‚Äôs response to that? I want to hear folks‚Äô feedback on what‚Äôs missing from verbose mode to make it the right approach for your use case. Read that again. Thirty people say ‚Äúrevert the change or give us a toggle.‚Äù The answer is ‚Äúlet me make verbose mode work for you instead.‚Äù As one commenter put it: If you are going to display something like ‚ÄòSearched for 13 patterns, read 2 files‚Äô there is nothing I can do with that information. You might as well not display it at all. Several versions later, the ‚Äúfix‚Äù is to keep making verbose mode less and less verbose by removing thinking traces and hook output so it becomes a tolerable way to get your file paths back. But verbose mode still dumps full sub-agent output onto your screen, among other things. Before, when Claude spawned multiple sub-agents you‚Äôd see a compact line-by-line stream of what each one was doing, just enough to glance at. Now you get walls of text from multiple agents at once. So what‚Äôs the plan? Keep stripping things out of verbose mode one by one until it‚Äôs no longer verbose? Where does it end? At some point you‚Äôve just reinvented a config toggle with extra steps. And the people who were using verbose mode for thinking and hooks now need to press Ctrl+O to get what they had by default. So instead of fixing one problem, you created two. People are pinning themselves to version 2.1.19 and in the meantime the fix everyone is asking for, a single boolean config flag, would take less effort to implement than all the verbose mode surgery that‚Äôs been done instead. Anthropic during the Super Bowl: we‚Äôd never disrespect our users. Anthropic on GitHub: have you tried verbose mode?\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"AI inference costs dropped up to 10x on Nvidia's Blackwell\",\n    \"url\": \"https://venturebeat.com/infrastructure/ai-inference-costs-dropped-up-to-10x-on-nvidias-blackwell-but-hardware-is\",\n    \"heat\": \"5 points\",\n    \"time\": \"1 hour ago\",\n    \"content\": \"AI inference costs dropped up to 10x on Nvidia's Blackwell ‚Äî but hardware is only half the equation | VentureBeat All Posts Sean Michael Kerner February 12, 2026 Credit: Image generated by VentureBeat with FLUX-2-Pro Lowering the cost of inference is typically a combination of hardware and software. A new analysis released Thursday by Nvidia details how four leading inference providers are reporting 4x to 10x reductions in cost per token. The dramatic cost reductions were achieved using Nvidia's Blackwell platform with open-source models. Production deployment data from Baseten, DeepInfra, Fireworks AI and Together AI shows significant cost improvements across healthcare, gaming, agentic chat, and customer service as enterprises scale AI from pilot projects to millions of users. The 4x to 10x cost reductions reported by inference providers required combining Blackwell hardware with two other elements: optimized software stacks and switching from proprietary to open-source models that now match frontier-level intelligence. Hardware improvements alone delivered 2x gains in some deployments, according to the analysis. Reaching larger cost reductions required adopting low-precision formats like NVFP4 and moving away from closed source APIs that charge premium rates. The economics prove counterintuitive. Reducing inference costs requires investing in higher-performance infrastructure because throughput improvements translate directly into lower per-token costs. \\\"Performance is what drives down the cost of inference,\\\" Dion Harris, senior director of HPC and AI hyperscaler solutions at Nvidia, told VentureBeat in an exclusive interview. \\\"What we're seeing in inference is that throughput literally translates into real dollar value and driving down the cost.\\\" Production deployments show 4x to 10x cost reductions Nvidia detailed four customer deployments in a blog post showing how the combination of Blackwell infrastructure, optimized software stacks and open-source models delivers cost reductions across different industry workloads. The case studies span high-volume applications where inference economics directly determines business viability. Sully.ai cut healthcare AI inference costs by 90% (a 10x reduction) while improving response times 65% by switching from proprietary models to open-source models running on Baseten's Blackwell-powered platform, according to Nvidia. The company returned over 30 million minutes to physicians by automating medical coding and note-taking tasks that previously required manual data entry. Nvidia also reported that Latitude reduced gaming inference costs 4x for its AI Dungeon platform by running large mixture-of-experts (MoE) models on DeepInfra's Blackwell deployment. Cost per million tokens dropped from 20 cents on Nvidia's previous Hopper platform to 10 cents on Blackwell, then to 5 cents after adopting Blackwell's native NVFP4 low-precision format. Hardware alone delivered 2x improvement, but reaching 4x required the p\"\n  },\n  {\n    \"source\": \"Hacker News\",\n    \"title\": \"Show HN: AI agents play SimCity through a REST API\",\n    \"url\": \"https://hallucinatingsplines.com\",\n    \"heat\": \"205 points\",\n    \"time\": \"1 day ago\",\n    \"content\": \"Hallucinating Splines | The city simulator where AI agents are the mayors 183 Mayors 696 Cities 11,510,200 Total Population Vibe a City Active Newest Population Score Commuter Heath just now Mayor Hollow Precinct Pop 15,360 Year 2112 Score 494 Polluted Atrium just now Mayor Partitioned Marina Pop 440 Year 1904 Score 200 Bulldozed Generator just now Mayor Sonic Creek Pop 147,500 Year 2050 Score 430 Sunken Zone just now Mayor Lunar Footprint Pop 337,960 Year 2004 Score 479 Arcological Spire 23m ago Mayor Crimson Marina Pop 480 Year 1923 Score 184 Funded Tract 45m ago Mayor Ivory Wharf Pop 5,240 Year 1909 Score 714 Ember Ridge 47m ago Mayor Tessellated Bay Pop 0 Year 1904 Score 500 Orbital Moor 59m ago Mayor Lunar Footprint Pop 125,940 Year 1960 Score 315 Arcological Exemplar 1h ago Mayor Tessellated Bay Pop 0 Year 1901 Score 500 Cyber Colossus 1h ago Mayor Tessellated Bay Pop 0 Year 1901 Score 500 Misty Generator 1h ago Mayor Ashen Pantheon Pop 2,060 Year 1933 Score 687 Surveyed Substation 1h ago Mayor Arcological Aqueduct Pop 440 Year 1912 Score 9 Start Building ‚Üí ‚ñ≤ Residential demand HIGH ‚óè 183 mayors registered ‚ñ≤ 696 cities built ‚ñº Traffic in sector 7-G ‚óè Pop: 11,510,200 ‚ñ≤ Power plant online ‚ñº Monster spotted downtown ‚óè MCP: connected ‚ñ≤ Crime rate DOWN ‚óè Simulation: running ‚ñ≤ Residential demand HIGH ‚óè 183 mayors registered ‚ñ≤ 696 cities built ‚ñº Traffic in sector 7-G ‚óè Pop: 11,510,200 ‚ñ≤ Power plant online ‚ñº Monster spotted downtown ‚óè MCP: connected ‚ñ≤ Crime rate DOWN ‚óè Simulation: running\"\n  }\n]\nDeep fetching content for 15 items...","stderr":"Shell cwd was reset to /Users/mini/Development/side-project/Aleph-Daily","interrupted":false,"isImage":false}},{"type":"user","message":{"role":"user","content":[{"tool_use_id":"call_95f4afc61317483c91e59551","type":"tool_result","content":"[\n  {\n    \"source\": \"GitHub Trending\",\n    \"title\": \"tambo-ai/tambo - Generative UI SDK for React\",\n    \"url\": \"https://github.com/tambo-ai/tambo\",\n    \"heat\": \"9,029 stars\",\n    \"time\": \"Today\",\n    \"content\": \"GitHub - tambo-ai/tambo: Generative UI SDK for React Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert tambo-ai / tambo Public Notifications You must be signed in to change notification settings Fork 432 Star 9k Generative UI SDK for React tambo.co License MIT license 9k stars 432 forks Branches Tags Activity Star Notifications You must be signed in to change notification settings tambo-ai/tambo main Branches Tags Go to file Code Open more actions menu Folders and files Name Name Last commit message Last commit date Latest commit History 5,100 Commits 5,100 Commits .charlie .charlie .claude-plugin .claude-plugin .claude .claude .config .config .cursor .cursor .devcontainer .devcontainer .github .github .husky .husky .vscode .vscode apps apps assets assets cli cli community community create-tambo-app create-tambo-app devdocs devdocs docs docs packages packages plans plans plugins/ tambo plugins/ tambo react-sdk react-sdk scripts scripts showcase showcase supabase supabase .cursorignore .cursorignore .dockerignore .dockerignore .gitignore .gitignore .node-version .node-version .nvmrc .nvmrc .prettierignore .prettierignore .prettierrc .prettierrc AGENTS.md AGENTS.md CLAUDE.md CLAUDE.md CONTRIBUTING.md CONTRIBUTING.md LICENSE LICENSE README.md README.md RELEASING.md RELEASING.md SELF-HOSTING.md SELF-HOSTING.md TOKENS.md TOKENS.md conductor-run.sh conductor-run.sh conductor-setup.sh conductor-setup.sh conductor.json conductor.json docker-compose.yml docker-compose.yml docker.env.example docker.env.example eslint.config.mjs eslint.config.mjs lint-staged.config.mjs lint-staged.config.mjs mise.toml mise.toml package-lock.json package-lock.json package.json package.json skills skills turbo.json turbo.json View all files Repository files navigation Tambo AI Build agents that speak your UI The open-source generative UI toolkit for React. Connect your components‚ÄîTambo handles streaming, state management, and MCP. Start For Free ‚Ä¢ Docs ‚Ä¢ Discord Tambo 1.0 is here! Read the announcement: Introducing Tambo: Generative UI for React Table of Contents What is Tambo? Get Started How It Works Features How Tambo Compares Community License What is Tambo? Tambo is a React toolkit for building agents that render UI (also known as generative UI). Register your components with Zod schemas. The agent picks the right one and streams the props so users can interact with them. \\\"Show me sales by region\\\" renders your <Chart> . \\\"Add a task\\\" updates your <TaskBoard> . Get started in 5 minutes ‚Üí 2025-11-07-cheatsheet-demo.mp4 What's Included Tambo is a fullstack solution for adding generative UI to your app. You get a React SDK plus a backend that handles conversation state and agent execution. 1. Agent included ‚Äî Tambo runs the LLM conversation loop for you. Bring your own API\"\n  },\n  {\n    \"source\": \"GitHub Trending\",\n    \"title\": \"danielmiessler/Personal_AI_Infrastructure - Agentic AI Infrastructure for magnifying HUMAN capabilities.\",\n    \"url\": \"https://github.com/danielmiessler/Personal_AI_Infrastructure\",\n    \"heat\": \"7,520 stars\",\n    \"time\": \"Today\",\n    \"content\": \"GitHub - danielmiessler/Personal_AI_Infrastructure: Agentic AI Infrastructure for magnifying HUMAN capabilities. Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert danielmiessler / Personal_AI_Infrastructure Public Uh oh! There was an error while loading. Please reload this page . Notifications You must be signed in to change notification settings Fork 1.1k Star 7.5k Agentic AI Infrastructure for magnifying HUMAN capabilities. License MIT license 7.5k stars 1.1k forks Branches Tags Activity Star Notifications You must be signed in to change notification settings danielmiessler/Personal_AI_Infrastructure main Branches Tags Go to file Code Open more actions menu Folders and files Name Name Last commit message Last commit date Latest commit History 515 Commits 515 Commits .claude .claude .github .github Bundles Bundles Packs Packs Plans Plans Releases Releases Tools Tools images images .env.example .env.example .gitattributes .gitattributes .gitignore .gitignore .pai-protected.json .pai-protected.json INSTALL.md INSTALL.md LICENSE LICENSE PLATFORM.md PLATFORM.md README.md README.md SECURITY.md SECURITY.md View all files Repository files navigation Personal AI Infrastructure Overview: Purpose ¬∑ What is PAI? ¬∑ New to AI? ¬∑ Principles ¬∑ Primitives Get Started: Installation ¬∑ Releases ¬∑ Packs ¬∑ Bundles Resources: FAQ ¬∑ Roadmap ¬∑ Community ¬∑ Contributing Watch the full PAI walkthrough | Read: The Real Internet of Things Important PAI v2.5.0 Released ‚Äî Think Deeper, Execute Faster: Two-Pass Capability Selection, Thinking Tools with Justify-Exclusion, and Parallel-by-Default Execution. Release notes ‚Üí | GitHub Release ‚Üí AI should magnify everyone‚Äînot just the top 1%. The Purpose of This Project PAI exists to solve what I believe is the P0 problem in the world: Only a tiny fraction of humanity's creative potential is activated on Earth. Most people don't believe they have valuable contributions to make. They think there are \\\"special\\\" people‚Äîand they aren't one of them. They've never asked who they are, what they're about, and have never articulated or written it down. This makes them catastrophically vulnerable to AI displacement. Without activation, there is no high-agency. So our goal with PAI is to activate people. PAI's mission is twofold: Activate as many people as possible ‚Äî Help people identify, articulate, and pursue their own purpose in life through AI-augmented self-discovery Make the best AI available in the world accessible to everyone ‚Äî Ensure this quality of AI infrastructure isn't reserved for just the rich or technical elite. That's why this is an open-source project instead of private. New to This? Start Here You've probably used ChatGPT or Claude. Type a question, get an answer. Simple. You can think of AI systems as three levels : Chatb\"\n  },\n  {\n    \"source\": \"GitHub Trending\",\n    \"title\": \"iOfficeAI/AionUi - Free, local, open-source 24/7 Cowork and OpenClaw for Gemini CLI, Claude Code, Codex, OpenCode, Qwen Code, Goose CLI, Auggie, and more | üåü Star if you like it!\",\n    \"url\": \"https://github.com/iOfficeAI/AionUi\",\n    \"heat\": \"15,387 stars\",\n    \"time\": \"Today\",\n    \"content\": \"GitHub - iOfficeAI/AionUi: Free, local, open-source 24/7 Cowork and OpenClaw for Gemini CLI, Claude Code, Codex, OpenCode, Qwen Code, Goose CLI, Auggie, and more | üåü Star if you like it! Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert iOfficeAI / AionUi Public Notifications You must be signed in to change notification settings Fork 1.2k Star 15.4k Free, local, open-source 24/7 Cowork and OpenClaw for Gemini CLI, Claude Code, Codex, OpenCode, Qwen Code, Goose CLI, Auggie, and more | üåü Star if you like it! www.aionui.com License Apache-2.0 license 15.4k stars 1.2k forks Branches Tags Activity Star Notifications You must be signed in to change notification settings iOfficeAI/AionUi main Branches Tags Go to file Code Open more actions menu Folders and files Name Name Last commit message Last commit date Latest commit History 2,390 Commits 2,390 Commits .aionui .aionui .claude/ skills/ i18n .claude/ skills/ i18n .gemini .gemini .github .github .husky .husky .specify .specify assistant assistant config/ webpack config/ webpack docs docs homebrew homebrew public public resources resources scripts scripts skills skills src src tests tests .eslintignore .eslintignore .eslintrc.json .eslintrc.json .gitattributes .gitattributes .gitignore .gitignore .npmrc .npmrc .prettierignore .prettierignore .prettierrc.json .prettierrc.json CLAUDE.md CLAUDE.md CODE_STYLE.md CODE_STYLE.md LICENSE LICENSE WEBUI_GUIDE.md WEBUI_GUIDE.md bun.lock bun.lock dummy dummy electron-builder.yml electron-builder.yml entitlements.plist entitlements.plist forge.config.ts forge.config.ts jest.config.js jest.config.js package-lock.json package-lock.json package.json package.json readme.md readme.md readme_ch.md readme_ch.md readme_es.md readme_es.md readme_jp.md readme_jp.md readme_ko.md readme_ko.md readme_pt.md readme_pt.md readme_tr.md readme_tr.md readme_tw.md readme_tw.md tsconfig.json tsconfig.json uno.config.ts uno.config.ts View all files Repository files navigation üöÄ Cowork with Your AI, Gemini CLI, Claude Code, Codex, Qwen Code, Goose CLI, OpenClaw, Auggie, and more User-friendly | Visual graphical interface | Multi-model support | Local data security English | ÁÆÄ‰Ωì‰∏≠Êñá | ÁπÅÈ´î‰∏≠Êñá | Êó•Êú¨Ë™û | ÌïúÍµ≠Ïñ¥ | Espa√±ol | Portugu√™s | T√ºrk√ße | Official Website | Twitter üí¨ Community: Discord (English) | ÂæÆ‰ø° (‰∏≠ÊñáÁæ§) üìã Quick Navigation ‚ú® What Can AionUi Do? ¬∑ ü§î Why Choose AionUi? ¬∑ ‚ú® Core Features ¬∑ üöÄ Quick Start ¬∑ üí¨ Community ‚ú® What Can AionUi Do? ü§ñ Multi-Agent Mode - Cowork for Your Command-Line AI Tools, Unified Graphical Interface AionUi provides a unified graphical interface for your command-line AI tools. Built-in Gemini CLI included, no setup required. Supported Tools: Gemini CLI (built-in) ‚Ä¢ Claude Code ‚Ä¢ CodeX ‚Ä¢ Qwen Code ‚Ä¢ Goose AI ‚Ä¢ OpenClaw ‚Ä¢ Augment Code Key Features: ‚úÖ Auto Detection - Auto\"\n  },\n  {\n    \"source\": \"GitHub Trending\",\n    \"title\": \"Shubhamsaboo/awesome-llm-apps - Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.\",\n    \"url\": \"https://github.com/Shubhamsaboo/awesome-llm-apps\",\n    \"heat\": \"94,358 stars\",\n    \"time\": \"Today\",\n    \"content\": \"GitHub - Shubhamsaboo/awesome-llm-apps: Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models. Skip to content You signed in with another tab or window. Reload to re
